# import torch
# from ultralytics import YOLO
# import torch.nn.functional as F
# import cv2
# import numpy as np

# # âœ… 1. best_modified.pt ë¡œë“œ
# model = YOLO("/home/yun/fish_length/dataset/runs/segment/train8/weights/best_modified.pt")

# # âœ… 2. export ëª¨ë“œ ì„¤ì •
# model.model.model[-1].export = True
# model.model.eval()
# for m in model.model.modules():
#     m.eval()

# # âœ… 3. ì‹¤ì œ ì´ë¯¸ì§€ ê¸°ë°˜ ì…ë ¥ (ë”ë¯¸ ë§ê³  ì‹¤ì œ ì‚¬ì§„ìœ¼ë¡œ)
# image_path = "/home/yun/fish_length/dataset/test/images/-_7_jpg.rf.34e4a0a06fecc18d2ff555f38f9c7ce4.jpg"
# image = cv2.imread(image_path)
# image = cv2.resize(image, (640, 640))
# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
# input_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0  # [1, 3, 640, 640]

# # âœ… 4. export ëª¨ë“œì—ì„œ PyTorch ì¶”ë¡  â†’ confidence í™•ì¸
# with torch.no_grad():
#     cls, mask, proto = model.model(input_tensor)
#     print("ğŸ”¥ PyTorch export mode cls max:", cls.max())
#     print(f"ğŸ§ª shape match check â†’ cls: {cls.shape}, mask: {mask.shape}")

# # âœ… 5. ONNXë¡œ export
# torch.onnx.export(
#     model.model,
#     input_tensor,
#     "segment_v3.onnx",
#     opset_version=12,
#     input_names=["images"],
#     output_names=["output_cls", "output_mask", "proto"],
#     dynamic_axes={
#         "images": {0: "batch"},
#         "output_cls": {0: "batch", 1: "anchors"},
#         "output_mask": {0: "batch", 1: "anchors"},
#         "proto": {0: "batch"}
#     }
# )

# print("âœ… ONNX export ì„±ê³µ: segment_v3.onnx")
import torch
from ultralytics import YOLO
import torch.nn.functional as F
import cv2
import numpy as np

# âœ… 1. ëª¨ë¸ ë¡œë“œ
model = YOLO("/home/yun/fish_length/dataset/runs/segment/train8/weights/best_modified.pt")

# âœ… 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
image_path = "/home/yun/fish_length/dataset/test/images/-_7_jpg.rf.34e4a0a06fecc18d2ff555f38f9c7ce4.jpg"
image = cv2.imread(image_path)
image = cv2.resize(image, (640, 640))
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
input_tensor = torch.tensor(image_rgb).permute(2, 0, 1).unsqueeze(0).float() / 255.0  # [1, 3, 640, 640]

# âœ… 3. export = Falseì—ì„œ confidence í™•ì¸
model.model.model[-1].export = False
model.model.eval()
with torch.no_grad():
    cls_orig, _, _ = model.model(input_tensor)
    print("ğŸ” ì›ë˜ ëª¨ë¸ cls max:", cls_orig.max())

# âœ… 4. export ëª¨ë“œë¡œ ì „í™˜ ë° confidence í™•ì¸
model.model.model[-1].export = True
model.model.eval()
for m in model.model.modules():
    m.eval()

with torch.no_grad():
    cls_exp, mask_exp, proto_exp = model.model(input_tensor)
# âœ… 5. ONNX Export
onnx_path = "segment_v3.onnx"
torch.onnx.export(
    model.model,
    input_tensor,
    onnx_path,
    opset_version=12,
    input_names=["images"],
    output_names=["output_cls", "output_mask", "proto"],
    dynamic_axes={
        "images": {0: "batch"},
        "output_cls": {0: "batch", 1: "anchors"},
        "output_mask": {0: "batch", 1: "anchors"},
        "proto": {0: "batch"}
    }
)

print(f"âœ… ONNX export ì„±ê³µ: {onnx_path}")
